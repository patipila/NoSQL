# Start from Jupyter base image
FROM jupyter/base-notebook:python-3.11

USER root

# Install Java 17 (matching Spark workers)
RUN apt-get update && \
    apt-get install -y openjdk-17-jdk-headless curl && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64

# Install Spark 3.5.3 (EXACT VERSION as workers)
ENV SPARK_VERSION=3.5.3
ENV HADOOP_VERSION=3
ENV SPARK_HOME=/opt/spark

RUN curl -sL "https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION}.tgz" | \
    tar xz -C /opt && \
    mv /opt/spark-${SPARK_VERSION}-bin-hadoop${HADOOP_VERSION} ${SPARK_HOME} && \
    chown -R ${NB_UID}:${NB_GID} ${SPARK_HOME}

# Set Spark environment variables
ENV PATH="${SPARK_HOME}/bin:${PATH}"
ENV PYTHONPATH="${SPARK_HOME}/python:${SPARK_HOME}/python/lib/py4j-0.10.9.7-src.zip:${PYTHONPATH}"
ENV PYSPARK_PYTHON=python3
ENV PYSPARK_DRIVER_PYTHON=jupyter

USER ${NB_UID}

# Install Python packages
RUN pip install --no-cache-dir \
    pyspark==3.5.3 \
    pymongo==4.6.0 \
    pandas==2.1.4 \
    numpy==1.26.2 \
    matplotlib==3.8.2 \
    seaborn==0.13.0 \
    scikit-learn==1.3.2 \
    jupyter-notebook

# Create directories
RUN mkdir -p /home/jovyan/work \
    /home/jovyan/data \
    /home/jovyan/src \
    /home/jovyan/config \
    /home/jovyan/reports/figures

WORKDIR /home/jovyan

CMD ["start-notebook.sh"]